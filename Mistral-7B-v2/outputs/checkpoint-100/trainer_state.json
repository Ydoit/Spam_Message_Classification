{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.05,
  "eval_steps": 500,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 13.09056282043457,
      "learning_rate": 0.00019805941782534764,
      "loss": 3.6036,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 13.26341724395752,
      "learning_rate": 0.00019605881764529358,
      "loss": 3.456,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.755516052246094,
      "learning_rate": 0.00019405821746523957,
      "loss": 2.5921,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.873948574066162,
      "learning_rate": 0.00019205761728518557,
      "loss": 2.1617,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.816888809204102,
      "learning_rate": 0.00019005701710513156,
      "loss": 2.0076,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.413206577301025,
      "learning_rate": 0.00018805641692507753,
      "loss": 1.8072,
      "step": 6
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.676034450531006,
      "learning_rate": 0.00018605581674502352,
      "loss": 1.6126,
      "step": 7
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.5750935077667236,
      "learning_rate": 0.00018405521656496952,
      "loss": 1.3208,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.531737327575684,
      "learning_rate": 0.00018205461638491548,
      "loss": 1.581,
      "step": 9
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.194148540496826,
      "learning_rate": 0.00018005401620486148,
      "loss": 1.307,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.1451189517974854,
      "learning_rate": 0.00017805341602480744,
      "loss": 1.3715,
      "step": 11
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.077394962310791,
      "learning_rate": 0.00017605281584475344,
      "loss": 1.3499,
      "step": 12
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.9344661235809326,
      "learning_rate": 0.00017405221566469943,
      "loss": 1.2842,
      "step": 13
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.987521171569824,
      "learning_rate": 0.00017205161548464542,
      "loss": 1.4329,
      "step": 14
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.947594404220581,
      "learning_rate": 0.00017005101530459136,
      "loss": 1.3589,
      "step": 15
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.0510542392730713,
      "learning_rate": 0.00016805041512453736,
      "loss": 1.587,
      "step": 16
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.7671420574188232,
      "learning_rate": 0.00016604981494448335,
      "loss": 1.3743,
      "step": 17
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.0957236289978027,
      "learning_rate": 0.00016404921476442935,
      "loss": 1.3996,
      "step": 18
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.137759208679199,
      "learning_rate": 0.0001620486145843753,
      "loss": 1.3758,
      "step": 19
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.5253686904907227,
      "learning_rate": 0.0001600480144043213,
      "loss": 1.3991,
      "step": 20
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.222471237182617,
      "learning_rate": 0.0001580474142242673,
      "loss": 1.5847,
      "step": 21
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.6138601303100586,
      "learning_rate": 0.00015604681404421327,
      "loss": 1.3638,
      "step": 22
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.395751714706421,
      "learning_rate": 0.00015404621386415926,
      "loss": 1.2547,
      "step": 23
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.1418297290802,
      "learning_rate": 0.00015204561368410523,
      "loss": 1.3715,
      "step": 24
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.8413426876068115,
      "learning_rate": 0.00015004501350405122,
      "loss": 1.3017,
      "step": 25
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.085839748382568,
      "learning_rate": 0.00014804441332399721,
      "loss": 1.3395,
      "step": 26
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.401181221008301,
      "learning_rate": 0.0001460438131439432,
      "loss": 1.4166,
      "step": 27
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.8167459964752197,
      "learning_rate": 0.00014404321296388918,
      "loss": 1.4492,
      "step": 28
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.600558042526245,
      "learning_rate": 0.00014204261278383514,
      "loss": 1.5777,
      "step": 29
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.244865655899048,
      "learning_rate": 0.00014004201260378114,
      "loss": 1.4673,
      "step": 30
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.707953929901123,
      "learning_rate": 0.00013804141242372713,
      "loss": 1.5156,
      "step": 31
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.684056282043457,
      "learning_rate": 0.00013604081224367312,
      "loss": 1.6554,
      "step": 32
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.167386054992676,
      "learning_rate": 0.0001340402120636191,
      "loss": 1.4661,
      "step": 33
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.0447888374328613,
      "learning_rate": 0.00013203961188356508,
      "loss": 1.2519,
      "step": 34
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.902560234069824,
      "learning_rate": 0.00013003901170351108,
      "loss": 1.3234,
      "step": 35
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.7506179809570312,
      "learning_rate": 0.00012803841152345704,
      "loss": 1.6239,
      "step": 36
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.4377429485321045,
      "learning_rate": 0.000126037811343403,
      "loss": 1.2356,
      "step": 37
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.567249059677124,
      "learning_rate": 0.000124037211163349,
      "loss": 1.2957,
      "step": 38
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.4270105361938477,
      "learning_rate": 0.000122036610983295,
      "loss": 1.4798,
      "step": 39
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.2742457389831543,
      "learning_rate": 0.00012003601080324098,
      "loss": 1.3765,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.870448112487793,
      "learning_rate": 0.00011803541062318697,
      "loss": 1.3841,
      "step": 41
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.023961305618286,
      "learning_rate": 0.00011603481044313295,
      "loss": 1.6939,
      "step": 42
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.935547113418579,
      "learning_rate": 0.00011403421026307892,
      "loss": 1.5669,
      "step": 43
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.2862279415130615,
      "learning_rate": 0.00011203361008302491,
      "loss": 1.4419,
      "step": 44
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.6631898880004883,
      "learning_rate": 0.0001100330099029709,
      "loss": 1.2444,
      "step": 45
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.713409662246704,
      "learning_rate": 0.00010803240972291689,
      "loss": 1.2455,
      "step": 46
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.2905948162078857,
      "learning_rate": 0.00010603180954286287,
      "loss": 1.5815,
      "step": 47
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.0639426708221436,
      "learning_rate": 0.00010403120936280886,
      "loss": 1.3037,
      "step": 48
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.4698777198791504,
      "learning_rate": 0.00010203060918275482,
      "loss": 1.27,
      "step": 49
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.8917436599731445,
      "learning_rate": 0.00010003000900270081,
      "loss": 1.5171,
      "step": 50
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.825582265853882,
      "learning_rate": 9.802940882264679e-05,
      "loss": 1.4998,
      "step": 51
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.011132001876831,
      "learning_rate": 9.602880864259278e-05,
      "loss": 1.1659,
      "step": 52
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.5015869140625,
      "learning_rate": 9.402820846253876e-05,
      "loss": 1.0314,
      "step": 53
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.5350396633148193,
      "learning_rate": 9.202760828248476e-05,
      "loss": 1.1036,
      "step": 54
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.4549155235290527,
      "learning_rate": 9.002700810243074e-05,
      "loss": 1.0044,
      "step": 55
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.005009651184082,
      "learning_rate": 8.802640792237672e-05,
      "loss": 1.2819,
      "step": 56
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.5236427783966064,
      "learning_rate": 8.602580774232271e-05,
      "loss": 1.2052,
      "step": 57
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.901517868041992,
      "learning_rate": 8.402520756226868e-05,
      "loss": 1.2719,
      "step": 58
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.5300188064575195,
      "learning_rate": 8.202460738221467e-05,
      "loss": 1.1378,
      "step": 59
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.457867383956909,
      "learning_rate": 8.002400720216065e-05,
      "loss": 1.285,
      "step": 60
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.252725839614868,
      "learning_rate": 7.802340702210663e-05,
      "loss": 1.6898,
      "step": 61
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.7157211303710938,
      "learning_rate": 7.602280684205261e-05,
      "loss": 1.3798,
      "step": 62
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.9637610912323,
      "learning_rate": 7.402220666199861e-05,
      "loss": 1.1431,
      "step": 63
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.1544039249420166,
      "learning_rate": 7.202160648194459e-05,
      "loss": 1.1193,
      "step": 64
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.6066858768463135,
      "learning_rate": 7.002100630189057e-05,
      "loss": 1.165,
      "step": 65
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.687236785888672,
      "learning_rate": 6.802040612183656e-05,
      "loss": 1.1459,
      "step": 66
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.8425099849700928,
      "learning_rate": 6.601980594178254e-05,
      "loss": 1.3919,
      "step": 67
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.3700761795043945,
      "learning_rate": 6.401920576172852e-05,
      "loss": 1.378,
      "step": 68
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.5220589637756348,
      "learning_rate": 6.20186055816745e-05,
      "loss": 1.2666,
      "step": 69
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.5905885696411133,
      "learning_rate": 6.001800540162049e-05,
      "loss": 1.24,
      "step": 70
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.023526430130005,
      "learning_rate": 5.801740522156648e-05,
      "loss": 1.1798,
      "step": 71
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.6401987075805664,
      "learning_rate": 5.601680504151246e-05,
      "loss": 1.2183,
      "step": 72
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.772580146789551,
      "learning_rate": 5.4016204861458444e-05,
      "loss": 1.4057,
      "step": 73
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.2905731201171875,
      "learning_rate": 5.201560468140443e-05,
      "loss": 1.0487,
      "step": 74
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.608537197113037,
      "learning_rate": 5.0015004501350405e-05,
      "loss": 1.102,
      "step": 75
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.6663308143615723,
      "learning_rate": 4.801440432129639e-05,
      "loss": 0.9882,
      "step": 76
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.71519136428833,
      "learning_rate": 4.601380414124238e-05,
      "loss": 1.2416,
      "step": 77
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.821091413497925,
      "learning_rate": 4.401320396118836e-05,
      "loss": 1.0357,
      "step": 78
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.9722838401794434,
      "learning_rate": 4.201260378113434e-05,
      "loss": 1.0769,
      "step": 79
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.566108226776123,
      "learning_rate": 4.0012003601080326e-05,
      "loss": 1.4041,
      "step": 80
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.744863986968994,
      "learning_rate": 3.801140342102631e-05,
      "loss": 1.1739,
      "step": 81
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.6235835552215576,
      "learning_rate": 3.6010803240972294e-05,
      "loss": 1.3358,
      "step": 82
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.5545310974121094,
      "learning_rate": 3.401020306091828e-05,
      "loss": 1.0153,
      "step": 83
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.1808059215545654,
      "learning_rate": 3.200960288086426e-05,
      "loss": 0.9537,
      "step": 84
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.6254830360412598,
      "learning_rate": 3.0009002700810245e-05,
      "loss": 1.109,
      "step": 85
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.5963499546051025,
      "learning_rate": 2.800840252075623e-05,
      "loss": 1.3965,
      "step": 86
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.665139675140381,
      "learning_rate": 2.6007802340702216e-05,
      "loss": 1.2601,
      "step": 87
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.794814109802246,
      "learning_rate": 2.4007202160648196e-05,
      "loss": 1.1145,
      "step": 88
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.525360584259033,
      "learning_rate": 2.200660198059418e-05,
      "loss": 1.1704,
      "step": 89
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.127640724182129,
      "learning_rate": 2.0006001800540163e-05,
      "loss": 1.157,
      "step": 90
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.989954948425293,
      "learning_rate": 1.8005401620486147e-05,
      "loss": 1.2346,
      "step": 91
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.435093879699707,
      "learning_rate": 1.600480144043213e-05,
      "loss": 1.2413,
      "step": 92
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.229224443435669,
      "learning_rate": 1.4004201260378114e-05,
      "loss": 0.9787,
      "step": 93
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.3658864498138428,
      "learning_rate": 1.2003601080324098e-05,
      "loss": 1.6424,
      "step": 94
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.948065757751465,
      "learning_rate": 1.0003000900270082e-05,
      "loss": 1.3589,
      "step": 95
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.355879306793213,
      "learning_rate": 8.002400720216065e-06,
      "loss": 1.1254,
      "step": 96
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.5062458515167236,
      "learning_rate": 6.001800540162049e-06,
      "loss": 1.4485,
      "step": 97
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.997905969619751,
      "learning_rate": 4.001200360108033e-06,
      "loss": 1.092,
      "step": 98
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.4625661373138428,
      "learning_rate": 2.0006001800540163e-06,
      "loss": 1.0273,
      "step": 99
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.9553818702697754,
      "learning_rate": 0.0,
      "loss": 1.4244,
      "step": 100
    }
  ],
  "logging_steps": 1,
  "max_steps": 100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 2791872603095040.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
